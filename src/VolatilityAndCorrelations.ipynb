{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility and Correlations\n",
    "\n",
    "In this notebook, we calculate risk factor returns and estimate volatilities and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from describe_data_set import \\\n",
    "    describe_values, \\\n",
    "    describe_dates, \\\n",
    "    normalised_term, \\\n",
    "    plot_data_table, \\\n",
    "    plot_volatility_distribution, \\\n",
    "    plot_correlation_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use stored consolidated data. The stored data originates from [ParseInputData](ParseInputData.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/consolidated/\"\n",
    "file_name = \"data_set_full.csv\"\n",
    "\n",
    "zipped_file_name = file_name + \".xz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with lzma.open(path + zipped_file_name) as zf:\n",
    "    file_content = zf.read()\n",
    "    with open(path + file_name, \"wb\") as f:\n",
    "        f.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_full = pd.read_csv(path + file_name)\n",
    "data_set_full[\"DATE\"] = pd.to_datetime(data_set_full[\"DATE\"])\n",
    "data_set_full[\"TERM\"] = data_set_full[\"TERM\"].fillna(\"\")\n",
    "print(data_set_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = pd.Timestamp(\"2004-09-07\")\n",
    "last_date = pd.Timestamp(\"2024-04-30\")\n",
    "\n",
    "currencies = [ \"EUR\", \"USD\", \"GBP\", \"USD-EUR\", \"GBP-EUR\" ]\n",
    "# terms = [\"\", \"1Y\", \"5Y\", \"10Y\"]\n",
    "terms = [\"\", \"1Y\", \"2Y\", \"5Y\", \"10Y\", \"20Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set_full[\n",
    "    (data_set_full[\"DATE\"] >= first_date) &\n",
    "    (data_set_full[\"DATE\"] <= last_date) &\n",
    "    data_set_full[\"CURRENCY\"].isin(currencies) &\n",
    "    data_set_full[\"TERM\"].isin(terms)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the available data are of equal length and that there are no gaps (except for weekends and bank holidays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_dates(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also double-check that available data is plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_values(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Interpolation\n",
    "\n",
    "Data gaps due to weekends and bank holidays require special treatment.\n",
    "\n",
    "We choose to model time a calender time. Furthermore, we assume that time series correspond to continuous stochastic processes. As proxy for the actual time series at gap dates we choose linear interpolation of neighbouring data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cols = pd.MultiIndex(levels=[[],[],], codes=[[],[],], names=[\"CURRENCY\", \"MONTHS\",])\n",
    "all_days = pd.DataFrame(index=pd.date_range(first_date, last_date, freq='d'), columns=empty_cols)\n",
    "data_table = pd.pivot_table(data_set, index=\"DATE\", columns=[\"CURRENCY\", \"MONTHS\"], values=\"VALUE\", aggfunc=\"sum\")\n",
    "data_table = pd.merge(all_days, data_table, left_index=True, right_index=True, how=\"left\")\n",
    "data_table = data_table.interpolate(method='linear', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "To get some intuition about the dat we plot normalised time series for FX rates and interest rates.\n",
    "\n",
    "FX rates are converted to log-rates.\n",
    "\n",
    "Furthermore, FX log-rates and interest rates are shifted to start in zero. This aims at making time series plots comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_table(data_table[[\"USD-EUR\", \"GBP-EUR\"]]).show()\n",
    "plot_data_table(data_table[[\"EUR\",]]).show()\n",
    "plot_data_table(data_table[[\"USD\",]]).show()\n",
    "plot_data_table(data_table[[\"GBP\",]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Calculation\n",
    "\n",
    "We calculate $n$-day overlapping returns. For this analysis, we set $n=30$. That is, returns correspond to monthly returns.\n",
    "\n",
    "Selection of non-overlapping returns and sub-sampling is handled by subsequent data analysis.\n",
    "\n",
    "For FX rates, we calculate log-prices and consequently log-returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_days = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = data_table.copy()\n",
    "table[\"USD-EUR\"] = np.log(table[\"USD-EUR\"])\n",
    "table[\"GBP-EUR\"] = np.log(table[\"GBP-EUR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_table = pd.DataFrame(\n",
    "    index = table.index[return_days:],\n",
    "    columns = table.columns,\n",
    "    data = table.values[return_days:,:] - table.values[:-return_days,:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of the overlapping return sample provide a first indication of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_table.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, that standard deviation is calculated for monthly returns. A corresponding annualised volatility can be calculated by multiplying standard deviation by $\\sqrt{365/30}\\approx 3.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility for Non-Overlapping Returns\n",
    "\n",
    "Overlapping returns exhibit considerable auto-correlation. To eliminate this feature from the data set we select sub-samples of non-overlapping returns.\n",
    "\n",
    "For our data set of daily observations and $n$-day returns we can select $n$ subsamples of non-overlapping returns.\n",
    "\n",
    "There is no natural criteria which subsample is to be used for estimating properties of returns. Consequently, we calculate standard deviation and annualised volatility for each sub-sample. The distribution across sub-samples is used as an indication of the uncertainty for our estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_table = pd.DataFrame()\n",
    "end_idx = return_table.shape[0]\n",
    "for offset in range(return_days):\n",
    "    std_table[offset] = return_table.iloc[offset:end_idx:return_days].describe().T[\"std\"]\n",
    "std_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect the volatility distribution via box-plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_volatility_distribution(std_table.T[[\"USD-EUR\", \"GBP-EUR\"]], return_days).show()\n",
    "plot_volatility_distribution(std_table.T[[\"EUR\",]], return_days).show()\n",
    "plot_volatility_distribution(std_table.T[[\"USD\",]], return_days).show()\n",
    "plot_volatility_distribution(std_table.T[[\"GBP\",]], return_days).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations of Non-Overlapping Returns\n",
    "\n",
    "For correlation estimation, we also use sub-samples of non-overlapping returns.\n",
    "\n",
    "Correlations are claculated for risk factor pairs. We will analyse the following sets of risk factor pairs:\n",
    "  - Interest rate risk factors within a single currency,\n",
    "  - FX versus FX risk factors,\n",
    "  - FX versus interest rates risk factors, and\n",
    "  - interest rate risk factors from different currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations(\n",
    "    return_table,\n",
    "    col_pair_list,\n",
    "    return_days,\n",
    "    ):\n",
    "    table = pd.DataFrame(\n",
    "        columns = [ p[0][0]+\"_\"+normalised_term(p[0][1]/12)+\"__\"+ p[1][0]+\"_\"+normalised_term(p[1][1]/12) for p in col_pair_list],\n",
    "        index = range(return_days)\n",
    "    )\n",
    "    end_idx = return_table.shape[0]\n",
    "    for offset in range(return_days):\n",
    "        tmp = return_table.iloc[offset:end_idx:return_days]\n",
    "        table.loc[offset] = [ tmp[c[0]].corr(tmp[c[1]]) for c in col_pair_list ]\n",
    "    return table\n",
    "\n",
    "\n",
    "def make_correlation_idx_list(cols):\n",
    "    idx_list = []\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i+1,len(cols)):\n",
    "            idx_list.append( (cols[i], cols[j]) )\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Currency Interest Rate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = return_table.columns.get_loc_level(\"EUR\")[0]\n",
    "col_pair_list = make_correlation_idx_list(return_table.columns[s])\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = return_table.columns.get_loc_level(\"USD\")[0]\n",
    "col_pair_list = make_correlation_idx_list(return_table.columns[s])\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = return_table.columns.get_loc_level(\"GBP\")[0]\n",
    "col_pair_list = make_correlation_idx_list(return_table.columns[s])\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FX Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = return_table.columns.get_loc_level(\"GBP-EUR\")[0]\n",
    "gbp_eur = return_table.columns[s][0]\n",
    "gbp_eur = ('GBP-EUR', 0)\n",
    "usd_eur = ('USD-EUR', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBP-EUR versus USD-EUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_pair_list = [(gbp_eur, usd_eur),]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBP-EUR versus Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = return_table.columns[return_table.columns.get_loc_level(\"EUR\")[0]]\n",
    "col_pair_list = [(gbp_eur, k) for k in idx]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = return_table.columns[return_table.columns.get_loc_level(\"GBP\")[0]]\n",
    "col_pair_list = [(gbp_eur, k) for k in idx]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = return_table.columns[return_table.columns.get_loc_level(\"USD\")[0]]\n",
    "col_pair_list = [(gbp_eur, k) for k in idx]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USD-EUR versus Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = return_table.columns[return_table.columns.get_loc_level(\"EUR\")[0]]\n",
    "col_pair_list = [(usd_eur, k) for k in idx]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = return_table.columns[return_table.columns.get_loc_level(\"USD\")[0]]\n",
    "col_pair_list = [(usd_eur, k) for k in idx]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = return_table.columns[return_table.columns.get_loc_level(\"GBP\")[0]]\n",
    "col_pair_list = [(usd_eur, k) for k in idx]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rates versus Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = return_table.columns[return_table.columns.get_loc_level(\"EUR\")[0]]\n",
    "two = return_table.columns[return_table.columns.get_loc_level(\"USD\")[0]]\n",
    "col_pair_list = [(a, b) for a in one for b in two]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = return_table.columns[return_table.columns.get_loc_level(\"EUR\")[0]]\n",
    "two = return_table.columns[return_table.columns.get_loc_level(\"GBP\")[0]]\n",
    "col_pair_list = [(a, b) for a in one for b in two]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = return_table.columns[return_table.columns.get_loc_level(\"GBP\")[0]]\n",
    "two = return_table.columns[return_table.columns.get_loc_level(\"USD\")[0]]\n",
    "col_pair_list = [(a, b) for a in one for b in two]\n",
    "plot_correlation_distribution(correlations(return_table, col_pair_list, return_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result Data\n",
    "\n",
    "We save the volatility and correlation estimates for subsequent model calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"standard_deviation_\" + str(return_days) + \"days.csv\"\n",
    "std_table.to_csv(path + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_pair_list = make_correlation_idx_list(return_table.columns)\n",
    "multi_idx = pd.MultiIndex.from_tuples([ (t[0][0], t[0][1], t[1][0], t[1][1]) for t in col_pair_list ], names=[\"CURRENCY1\", \"MONTHS1\", \"CURRENCY1\", \"MONTHS2\"])\n",
    "corrs_table = correlations(return_table, col_pair_list, return_days)\n",
    "corrs_table.columns = multi_idx\n",
    "# corrs_table.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"correlations_\" + str(return_days) + \"days.csv\"\n",
    "corrs_table.T.to_csv(path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InterestRateModelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
