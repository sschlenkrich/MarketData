{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Input Data\n",
    "\n",
    "This notebook implements data parsing and data normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECB Data\n",
    "\n",
    "ECB data are EUR yield curves and EUR-denominated FX rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/input/ecb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FX Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"ECB Data Portal_20240512160936_fx.csv\"\n",
    "data = pd.read_csv(path + file_name)\n",
    "data = data.drop([\"TIME PERIOD\"], axis=1)\n",
    "data = data.rename(\n",
    "    {\n",
    "        \"Swiss franc/Euro (EXR.D.CHF.EUR.SP00.A)\" : \"CHF-EUR\",\n",
    "        \"Chinese yuan renminbi/Euro (EXR.D.CNY.EUR.SP00.A)\" : \"CNY-EUR\",\n",
    "        \"UK pound sterling/Euro (EXR.D.GBP.EUR.SP00.A)\" : \"GBP-EUR\",\n",
    "        \"Japanese yen/Euro (EXR.D.JPY.EUR.SP00.A)\" : \"JPY-EUR\",\n",
    "        \"US dollar/Euro (EXR.D.USD.EUR.SP00.A)\" : \"USD-EUR\",\n",
    "    },\n",
    "    axis = 1,\n",
    ")\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"DATE\"])\n",
    "data_fx = data\n",
    "data_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 5, cols = 1, subplot_titles=(\"USD-EUR\", \"GBP-EUR\", \"CHF-EUR\", \"JPY-EUR\", \"CNY-EUR\"))\n",
    "fig.add_trace(go.Scatter(x=data[\"DATE\"], y=data[\"USD-EUR\"]), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=data[\"DATE\"], y=data[\"GBP-EUR\"]), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=data[\"DATE\"], y=data[\"CHF-EUR\"]), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=data[\"DATE\"], y=data[\"JPY-EUR\"]), row=4, col=1)\n",
    "fig.add_trace(go.Scatter(x=data[\"DATE\"], y=data[\"CNY-EUR\"]), row=5, col=1)\n",
    "fig.update_layout(height=900, width=1600, showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"ECB Data Portal_20240512160755_yc.csv\"\n",
    "data = pd.read_csv(path + file_name)\n",
    "data = data.drop([\"TIME PERIOD\"], axis=1)\n",
    "terms = [ label.split(\" \")[-1][1:-1].split(\"_\")[-1] for label in data.columns[1:] ]\n",
    "data = data.rename(dict( zip(data.columns[1:], terms)), axis = 1)\n",
    "cols = [ \"DATE\",\n",
    "    \"3M\", \"6M\", \"9M\", \"1Y\", \"2Y\", \"3Y\",\n",
    "    \"4Y\", \"5Y\", \"6Y\", \"7Y\", \"8Y\", \"9Y\",\n",
    "    \"10Y\", \"12Y\", \"15Y\", \"20Y\", \"25Y\", \"30Y\",\n",
    "]\n",
    "data = data[cols]\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"DATE\"])\n",
    "data_ecb = data\n",
    "data_ecb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data, x=\"DATE\", y=data.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UK Bank of England Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/input/boe/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalised_term(years):\n",
    "    months = round(12*years)\n",
    "    y = months // 12\n",
    "    m = months % 12\n",
    "    term = \"\"\n",
    "    if y > 0:\n",
    "        term = term + str(y) + \"Y\"\n",
    "    if m > 0:\n",
    "        term = term + str(m) + \"M\"\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boe_data(path, file_name, sheet_name):\n",
    "    data = pd.read_excel(path + file_name, sheet_name=sheet_name, header=3)\n",
    "    data = data.drop(0, axis=0)\n",
    "    data = data.rename({ \"years:\" : \"DATE\" }, axis=1)\n",
    "    data[\"DATE\"] = pd.to_datetime(data[\"DATE\"])\n",
    "    # terms = [ str(round(12*y)) + \"M\" for y in data.columns[1:]]\n",
    "    terms = [ normalised_term(y) for y in data.columns[1:]]\n",
    "    data = data.rename(dict( zip(data.columns[1:], terms)), axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2000 - 2004, Short End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"GLC Nominal daily data_2000 to 2004.xlsx\"\n",
    "sheet_name = \"3. nominal spot, short end\"\n",
    "data_boe_1a = boe_data(path, file_name, sheet_name)\n",
    "data_boe_1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2000 - 2004, Long End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"GLC Nominal daily data_2000 to 2004.xlsx\"\n",
    "sheet_name = \"4. nominal spot curve\"\n",
    "data_boe_1b = boe_data(path, file_name, sheet_name)\n",
    "data_boe_1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2005 - 2015, Short End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"GLC Nominal daily data_2005 to 2015.xlsx\"\n",
    "sheet_name = \"3. spot, short end\"\n",
    "data_boe_2a = boe_data(path, file_name, sheet_name)\n",
    "data_boe_2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2005 - 2015, Long End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"GLC Nominal daily data_2005 to 2015.xlsx\"\n",
    "sheet_name = \"4. spot curve\"\n",
    "data_boe_2b = boe_data(path, file_name, sheet_name)\n",
    "data_boe_2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2016 - Present, Short End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"GLC Nominal daily data_2016 to present.xlsx\"\n",
    "sheet_name = \"3. spot, short end\"\n",
    "data_boe_3a = boe_data(path, file_name, sheet_name)\n",
    "data_boe_3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2016 - Present, Long End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"GLC Nominal daily data_2016 to present.xlsx\"\n",
    "sheet_name = \"4. spot curve\"\n",
    "data_boe_3b = boe_data(path, file_name, sheet_name)\n",
    "data_boe_3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US Treasury Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/input/us_treasury/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_data(path, file_name):\n",
    "    data = pd.read_csv(path + file_name)\n",
    "    data = data.rename({ \"Date\" : \"DATE\" }, axis=1)\n",
    "    terms = [ label.replace(\" \", \"\")[0:-1] for label in data.columns[1:] ]\n",
    "    data = data.rename(dict( zip(data.columns[1:], terms)), axis = 1)\n",
    "    try:\n",
    "        data[\"DATE\"] = pd.to_datetime(data[\"DATE\"], format=\"%m/%d/%y\")\n",
    "    except ValueError:\n",
    "        data[\"DATE\"] = pd.to_datetime(data[\"DATE\"], format=\"%m/%d/%Y\")\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"yield-curve-rates-1990-2023.csv\"\n",
    "data_us_1 = us_data(path, file_name)\n",
    "data_us_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"daily-treasury-rates.csv\"\n",
    "data_us_2 = us_data(path, file_name)\n",
    "data_us_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Selection and Data Normalisation\n",
    "\n",
    "In this section, we specify data selection and data normalisation. This is particularly relevant for yield curve data.\n",
    "\n",
    "**Yield Curve Terms**\n",
    "\n",
    "We select data for the following terms:\n",
    "\n",
    "3M,   6M,  9M,  1Y,  2Y,  3Y,\n",
    "4Y,   5Y,  6Y,  7Y,  8Y,  9Y,\n",
    "10Y, 12Y, 15Y, 20Y, 25Y, 30Y.\n",
    "\n",
    "If a term is not available for a data set then it is skipped.\n",
    "\n",
    "**Date Selection**\n",
    "\n",
    "We select all dates with available data from the data sets.\n",
    "\n",
    "Data set entries with *null* data are excluded.\n",
    "\n",
    "**Data Format**\n",
    "\n",
    "We store individual data points with the following properties (columns):\n",
    "  - DATE, observation date in format YYYY-MM-DD.\n",
    "  - CURRENCY, market currency in format CUR or currency pair in format FOR-DOM.\n",
    "  - TERM, maturity term as months or years, formatted as string, e.g. 6M, 2Y; empty for FX rates.\n",
    "  - MONTHS, maturity term in months; 0 for FX rates.\n",
    "  - VALUE, annual interest rate as decimal number with continuous compounding, FX rates as EUR-denominated price.\n",
    "  - DESCR, free text string, description of source and value format.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\n",
    "     \"3M\",  \"6M\", \"9M\",   \"1Y\",  \"2Y\",  \"3Y\",\n",
    "     \"4Y\",  \"5Y\",  \"6Y\",  \"7Y\",  \"8Y\",  \"9Y\",\n",
    "    \"10Y\", \"12Y\", \"15Y\", \"20Y\", \"25Y\", \"30Y\",\n",
    "]\n",
    "\n",
    "columns = [\"DATE\", \"CURRENCY\", \"TERM\", \"MONTHS\", \"VALUE\", \"DESC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def months_from_term(term):\n",
    "    val = int(term[0:-1])\n",
    "    unit = term[-1:]\n",
    "    if unit == \"M\":\n",
    "        return val\n",
    "    if unit == \"Y\":\n",
    "        return 12 * val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FX Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_fx.melt(\"DATE\", var_name=\"CURRENCY\", value_name=\"VALUE\")\n",
    "data[\"TERM\"] = \"\"\n",
    "data[\"MONTHS\"] = 0\n",
    "data[\"DESC\"] = \"ECB Data Portal\"\n",
    "data = data[columns]\n",
    "data_set_fx = data\n",
    "data_set_fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUR Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for term in terms:\n",
    "    # print(term, month)\n",
    "    month = months_from_term(term)\n",
    "    data = pd.DataFrame()\n",
    "    data[\"DATE\"] = data_ecb[\"DATE\"]\n",
    "    data[\"CURRENCY\"] = \"EUR\"\n",
    "    data[\"TERM\"] = term\n",
    "    data[\"MONTHS\"] = month\n",
    "    data[\"VALUE\"] = data_ecb[term] * 1.0e-2\n",
    "    data[\"DESC\"] = \"ECB Data Portal, continuous compounding, Act/365 (Fixed)\"\n",
    "    data_list.append(data)\n",
    "\n",
    "data_set_ecb = pd.concat(data_list, ignore_index=True)\n",
    "data_set_ecb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBP Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boe_a = pd.concat([data_boe_1a, data_boe_2a, data_boe_3a], ignore_index=True)\n",
    "data_boe_b = pd.concat([data_boe_1b, data_boe_2b, data_boe_3b], ignore_index=True)\n",
    "dt = [ dt.days for dt in (data_boe_a[\"DATE\"] - data_boe_b[\"DATE\"]) ]\n",
    "assert np.max(dt) == 0\n",
    "assert np.min(dt) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for term in terms:\n",
    "    month = months_from_term(term)\n",
    "    # print(term, month)\n",
    "    data = pd.DataFrame()\n",
    "    data[\"DATE\"] = data_boe_b[\"DATE\"]\n",
    "    data[\"CURRENCY\"] = \"GBP\"\n",
    "    data[\"TERM\"] = term\n",
    "    data[\"MONTHS\"] = month\n",
    "    if month < 12:\n",
    "        data[\"VALUE\"] = data_boe_a[term] * 1.0e-2\n",
    "    else:\n",
    "        data[\"VALUE\"] = data_boe_b[term] * 1.0e-2\n",
    "    data[\"DESC\"] = \"BoE Statistics Yield Curve, continuous compounding, Act/365 (Fixed)\"\n",
    "    data_list.append(data)\n",
    "\n",
    "data_set_boe = pd.concat(data_list, ignore_index=True)\n",
    "data_set_boe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USD Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_us = pd.concat([data_us_2, data_us_1], ignore_index=True)\n",
    "\n",
    "data_list = []\n",
    "for term in terms:\n",
    "    if not term in data_us.columns:\n",
    "        continue\n",
    "    month = months_from_term(term)\n",
    "    # print(term, month)\n",
    "    data = pd.DataFrame()\n",
    "    data[\"DATE\"] = data_us[\"DATE\"]\n",
    "    data[\"CURRENCY\"] = \"USD\"\n",
    "    data[\"TERM\"] = term\n",
    "    data[\"MONTHS\"] = month\n",
    "    rates = data_us[term] * 1.0e-2\n",
    "    if month <= 6:\n",
    "        cont_rates = np.log(1.0 + rates * month / 12.0) / (month / 12.0)\n",
    "    else:\n",
    "        cont_rates = np.log(np.power(1.0 + rates/2.0, 2 * month / 12)) / (month / 12.0)\n",
    "    data[\"VALUE\"] = cont_rates\n",
    "    data[\"DESC\"] = \"US Treasury Par Yield Curve Rates, continuous compounding, Act/365 (Fixed)\"\n",
    "    data_list.append(data)\n",
    "\n",
    "data_set_us = pd.concat(data_list, ignore_index=True)\n",
    "data_set_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidated Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.concat([ data_set_fx, data_set_ecb, data_set_boe, data_set_us ], ignore_index = True)\n",
    "data_set = data_set.dropna()\n",
    "data_set = data_set.sort_values([\"CURRENCY\", \"MONTHS\", \"DATE\"], ignore_index=True)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from describe_data_set import describe_values, describe_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_values(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_dates(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/consolidated/\"\n",
    "file_name = \"data_set_full.csv\"\n",
    "\n",
    "data_set.to_csv(path + file_name, index=False, float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also zip the output CSV file to store it efficiently in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + file_name, \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "with lzma.open(path + file_name + \".xz\", \"w\") as f:\n",
    "    f.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantLib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
